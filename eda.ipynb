{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from floortrans.loaders import FloorplanSVG\n",
    "from floortrans.loaders.augmentations import (RandomCropToSizeTorch,\n",
    "                                              ResizePaddedTorch,\n",
    "                                              Compose,\n",
    "                                              DictToTensor,\n",
    "                                              ColorJitterTorch,\n",
    "                                              RandomRotations)\n",
    "\n",
    "from torchinfo import summary\n",
    "\n",
    "from model.deeplabv3plus import DeepLabV3Plus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = 'data/cubicasa5k/'\n",
    "TRAIN_PATH = 'train.txt'\n",
    "VAL_PATH = 'val.txt'\n",
    "\n",
    "aug = Compose([\n",
    "    ResizePaddedTorch((0, 0), data_format='dict', size=(512, 512)),\n",
    "    DictToTensor()\n",
    "])\n",
    "\n",
    "train_data = FloorplanSVG(DATA_PATH, TRAIN_PATH, augmentations=aug, format='lmdb', is_transform=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Image Shape:', train_data[0]['image'].shape)\n",
    "print('Label Shape:', train_data[0]['label'].shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Image dtype:', train_data[0]['image'].dtype)\n",
    "print('Label dtype:', train_data[0]['label'].dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizing Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = train_data[10]\n",
    "\n",
    "# Convert back to [0, 255] range\n",
    "tensor_image = sample['image'] * 255.0\n",
    "\n",
    "np_image = tensor_image.numpy().astype(np.uint8)  # Convert to unsigned 8-bit integer\n",
    "\n",
    "# Transpose to [H, W, 3] from [3, H, W]\n",
    "np_image = np.transpose(np_image, (1, 2, 0))\n",
    "\n",
    "# Create figure with 1 row and 3 columns for the first set of visualizations\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 8))\n",
    "\n",
    "# Input image\n",
    "axes[0].imshow(np_image)\n",
    "axes[0].axis('off')\n",
    "axes[0].set_title('Input Image')\n",
    "\n",
    "# Room segmentation map\n",
    "axes[1].imshow(np_image)\n",
    "axes[1].imshow(sample['label'][21], alpha=0.8)\n",
    "axes[1].axis('off')\n",
    "axes[1].set_title('Room Labels')\n",
    "\n",
    "# Icon segmentation map\n",
    "axes[2].imshow(np_image)\n",
    "axes[2].imshow(sample['label'][22], alpha=0.8)\n",
    "axes[2].axis('off')\n",
    "axes[2].set_title('Icon Labels')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Now display the heatmaps, 3 heatmaps per row\n",
    "num_heatmaps = 21\n",
    "cols = 3\n",
    "rows = (num_heatmaps + cols - 1) // cols  # Calculate number of rows needed\n",
    "\n",
    "fig, axes = plt.subplots(rows, cols, figsize=(10, 3 * rows))\n",
    "\n",
    "for i in range(num_heatmaps):\n",
    "    row = i // cols\n",
    "    col = i % cols\n",
    "\n",
    "    axes[row, col].imshow(np_image)\n",
    "    axes[row, col].imshow(sample['label'][i], alpha=0.8)\n",
    "    axes[row, col].axis('off')\n",
    "    axes[row, col].set_title(f'Heatmap {i+1}')\n",
    "\n",
    "# If there are empty spaces in the last row (if heatmaps < total subplots), hide them\n",
    "for j in range(i + 1, rows * cols):\n",
    "    fig.delaxes(axes[j // cols, j % cols])  # Remove unused subplots\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "===================================================================================================================\n",
       "Layer (type:depth-idx)                                            Output Shape              Param #\n",
       "===================================================================================================================\n",
       "DeepLabV3Plus                                                     [25, 12, 256, 256]        --\n",
       "├─Backbone: 1-1                                                   [25, 24, 64, 64]          --\n",
       "│    └─EfficientNet: 2-1                                          --                        1,409,000\n",
       "│    │    └─Sequential: 3-1                                       --                        7,700,994\n",
       "├─ASPP: 1-2                                                       [25, 256, 8, 8]           --\n",
       "│    └─Conv2d: 2-2                                                [25, 256, 8, 8]           360,448\n",
       "│    └─AtrousConv: 2-3                                            [25, 256, 8, 8]           --\n",
       "│    │    └─DepthwiseSeparableConv: 3-2                           [25, 256, 8, 8]           373,632\n",
       "│    │    └─ChannelAttention: 3-3                                 [25, 256, 8, 8]           8,464\n",
       "│    └─AtrousConv: 2-4                                            [25, 256, 8, 8]           --\n",
       "│    │    └─DepthwiseSeparableConv: 3-4                           [25, 256, 8, 8]           373,632\n",
       "│    │    └─ChannelAttention: 3-5                                 [25, 256, 8, 8]           8,464\n",
       "│    └─AtrousConv: 2-5                                            [25, 256, 8, 8]           --\n",
       "│    │    └─DepthwiseSeparableConv: 3-6                           [25, 256, 8, 8]           373,632\n",
       "│    │    └─ChannelAttention: 3-7                                 [25, 256, 8, 8]           8,464\n",
       "│    └─Sequential: 2-6                                            [25, 256, 1, 1]           --\n",
       "│    │    └─AdaptiveAvgPool2d: 3-8                                [25, 1408, 1, 1]          --\n",
       "│    │    └─Conv2d: 3-9                                           [25, 256, 1, 1]           360,448\n",
       "│    │    └─BatchNorm2d: 3-10                                     [25, 256, 1, 1]           512\n",
       "│    │    └─ReLU: 3-11                                            [25, 256, 1, 1]           --\n",
       "│    └─Sequential: 2-7                                            [25, 256, 8, 8]           --\n",
       "│    │    └─Conv2d: 3-12                                          [25, 256, 8, 8]           327,680\n",
       "│    │    └─BatchNorm2d: 3-13                                     [25, 256, 8, 8]           512\n",
       "│    │    └─ReLU: 3-14                                            [25, 256, 8, 8]           --\n",
       "├─Decoder: 1-3                                                    [25, 12, 256, 256]        --\n",
       "│    └─Sequential: 2-8                                            [25, 48, 64, 64]          --\n",
       "│    │    └─Conv2d: 3-15                                          [25, 48, 64, 64]          1,152\n",
       "│    │    └─BatchNorm2d: 3-16                                     [25, 48, 64, 64]          96\n",
       "│    │    └─ReLU: 3-17                                            [25, 48, 64, 64]          --\n",
       "│    └─SpatialAttention: 2-9                                      [25, 256, 64, 64]         --\n",
       "│    │    └─Conv2d: 3-18                                          [25, 1, 64, 64]           98\n",
       "│    │    └─Sigmoid: 3-19                                         [25, 1, 64, 64]           --\n",
       "│    └─Sequential: 2-10                                           [25, 256, 64, 64]         --\n",
       "│    │    └─DepthwiseSeparableConv: 3-20                          [25, 256, 64, 64]         81,072\n",
       "│    │    └─DepthwiseSeparableConv: 3-21                          [25, 256, 64, 64]         68,352\n",
       "│    │    └─DepthwiseSeparableConv: 3-22                          [25, 256, 64, 64]         68,352\n",
       "│    └─Conv2d: 2-11                                               [25, 12, 64, 64]          3,084\n",
       "│    └─Conv2d: 2-12                                               [25, 11, 64, 64]          2,827\n",
       "│    └─Conv2d: 2-13                                               [25, 21, 64, 64]          5,397\n",
       "===================================================================================================================\n",
       "Total params: 11,536,312\n",
       "Trainable params: 11,536,312\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (Units.GIGABYTES): 47.79\n",
       "===================================================================================================================\n",
       "Input size (MB): 19.66\n",
       "Forward/backward pass size (MB): 7245.24\n",
       "Params size (MB): 40.51\n",
       "Estimated Total Size (MB): 7305.41\n",
       "==================================================================================================================="
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from model.deeplabv3plus import DeepLabV3Plus\n",
    "from torchinfo import summary\n",
    "\n",
    "model = DeepLabV3Plus(backbone='efficientnet_b2', attention=True).to('cuda')\n",
    "\n",
    "summary(model, input_size=(25, 3, 256, 256), device='cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.models import efficientnet_v2_m\n",
    "\n",
    "model = efficientnet_v2_m(weights='DEFAULT').to('cuda')\n",
    "\n",
    "print(model.features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize Class Frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

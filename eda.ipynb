{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from floortrans.loaders import FloorplanSVG\n",
    "from floortrans.loaders.augmentations import (RandomCropToSizeTorch,\n",
    "                                              ResizePaddedTorch,\n",
    "                                              Compose,\n",
    "                                              DictToTensor,\n",
    "                                              ColorJitterTorch,\n",
    "                                              RandomRotations)\n",
    "\n",
    "from torchinfo import summary\n",
    "\n",
    "from model.deeplabv3plus import DeepLabV3Plus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = 'data/cubicasa5k/'\n",
    "TRAIN_PATH = 'train.txt'\n",
    "VAL_PATH = 'val.txt'\n",
    "\n",
    "train_data = FloorplanSVG(DATA_PATH, TRAIN_PATH, format='lmdb', is_transform=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image Shape: torch.Size([3, 2480, 3507])\n",
      "Label Shape: torch.Size([2, 2480, 3507])\n"
     ]
    }
   ],
   "source": [
    "print('Image Shape:', train_data[0]['image'].shape)\n",
    "print('Label Shape:', train_data[0]['label'].shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image dtype: torch.uint8\n",
      "Label dtype: torch.uint8\n"
     ]
    }
   ],
   "source": [
    "print('Image dtype:', train_data[0]['image'].dtype)\n",
    "print('Label dtype:', train_data[0]['label'].dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'image': tensor([[[0, 0, 0,  ..., 0, 0, 0],\n",
       "          [0, 0, 0,  ..., 1, 0, 0],\n",
       "          [0, 0, 0,  ..., 1, 0, 0],\n",
       "          ...,\n",
       "          [1, 1, 1,  ..., 1, 0, 0],\n",
       "          [1, 1, 1,  ..., 0, 0, 0],\n",
       "          [1, 1, 1,  ..., 0, 0, 1]],\n",
       " \n",
       "         [[1, 0, 0,  ..., 0, 0, 0],\n",
       "          [1, 0, 0,  ..., 0, 0, 0],\n",
       "          [0, 0, 0,  ..., 0, 0, 0],\n",
       "          ...,\n",
       "          [1, 1, 1,  ..., 0, 0, 0],\n",
       "          [1, 1, 1,  ..., 0, 0, 0],\n",
       "          [1, 1, 1,  ..., 0, 0, 0]],\n",
       " \n",
       "         [[0, 1, 0,  ..., 0, 0, 0],\n",
       "          [0, 1, 0,  ..., 0, 0, 0],\n",
       "          [0, 1, 0,  ..., 0, 0, 0],\n",
       "          ...,\n",
       "          [1, 1, 1,  ..., 0, 0, 0],\n",
       "          [1, 1, 1,  ..., 0, 0, 0],\n",
       "          [1, 1, 1,  ..., 0, 0, 0]]], dtype=torch.uint8),\n",
       " 'label': tensor([[[0, 0, 0,  ..., 0, 0, 0],\n",
       "          [0, 0, 0,  ..., 0, 0, 0],\n",
       "          [0, 0, 0,  ..., 0, 0, 0],\n",
       "          ...,\n",
       "          [0, 0, 0,  ..., 0, 0, 0],\n",
       "          [0, 0, 0,  ..., 0, 0, 0],\n",
       "          [0, 0, 0,  ..., 0, 0, 0]],\n",
       " \n",
       "         [[0, 0, 0,  ..., 0, 0, 0],\n",
       "          [0, 0, 0,  ..., 0, 0, 0],\n",
       "          [0, 0, 0,  ..., 0, 0, 0],\n",
       "          ...,\n",
       "          [0, 0, 0,  ..., 0, 0, 0],\n",
       "          [0, 0, 0,  ..., 0, 0, 0],\n",
       "          [0, 0, 0,  ..., 0, 0, 0]]], dtype=torch.uint8),\n",
       " 'folder': '/high_quality_architectural/6044/',\n",
       " 'heatmaps': {0: [(1096, 156), (1826, 156), (1096, 338)],\n",
       "  1: [(1189, 1403), (1618, 1417)],\n",
       "  2: [(1096, 249)],\n",
       "  3: [(1554, 1208)],\n",
       "  4: [(1822, 1585), (1399, 1172)],\n",
       "  5: [(1101, 1585)],\n",
       "  6: [(1265, 1403), (1555, 1376)],\n",
       "  7: [(1625, 1208)],\n",
       "  8: [(1403, 559), (1301, 1172), (1409, 1403)],\n",
       "  9: [(1822, 559), (1403, 1016), (1553, 1403), (1625, 1376)],\n",
       "  10: [(1265, 1585), (1553, 1585), (1409, 1585), (1301, 1403)],\n",
       "  11: [(1101, 559), (1101, 1016), (1101, 1172), (1101, 1403)],\n",
       "  12: [(1553, 1403), (1553, 1403)],\n",
       "  13: [(1162, 558),\n",
       "   (1473, 558),\n",
       "   (1574, 558),\n",
       "   (1592, 1585),\n",
       "   (1323, 1585),\n",
       "   (1432, 1585),\n",
       "   (1149, 1585),\n",
       "   (1190, 1172),\n",
       "   (1436, 1402),\n",
       "   (1309, 1402)],\n",
       "  14: [(1358, 558),\n",
       "   (1566, 558),\n",
       "   (1775, 558),\n",
       "   (1743, 1585),\n",
       "   (1392, 1585),\n",
       "   (1538, 1585),\n",
       "   (1197, 1585),\n",
       "   (1268, 1172),\n",
       "   (1538, 1402),\n",
       "   (1400, 1402)],\n",
       "  15: [(1403, 845), (1300, 1192)],\n",
       "  16: [(1403, 934), (1300, 1278)],\n",
       "  17: [(1119, 942),\n",
       "   (1112, 942),\n",
       "   (1164, 942),\n",
       "   (1218, 942),\n",
       "   (1284, 942),\n",
       "   (1340, 942),\n",
       "   (1322, 1027),\n",
       "   (1276, 1027),\n",
       "   (1119, 1027),\n",
       "   (1183, 1027),\n",
       "   (1183, 1094),\n",
       "   (1225, 1027),\n",
       "   (1112, 1183),\n",
       "   (1194, 1495),\n",
       "   (1272, 1444),\n",
       "   (1337, 1483),\n",
       "   (1414, 1511),\n",
       "   (1556, 1315),\n",
       "   (1556, 1216),\n",
       "   (1559, 1424),\n",
       "   (1750, 1389),\n",
       "   (1748, 1283),\n",
       "   (1748, 1205)],\n",
       "  18: [(1164, 942),\n",
       "   (1119, 942),\n",
       "   (1218, 942),\n",
       "   (1284, 942),\n",
       "   (1340, 942),\n",
       "   (1395, 942),\n",
       "   (1386, 1027),\n",
       "   (1322, 1027),\n",
       "   (1183, 1027),\n",
       "   (1225, 1027),\n",
       "   (1276, 1094),\n",
       "   (1276, 1027),\n",
       "   (1154, 1183),\n",
       "   (1259, 1495),\n",
       "   (1283, 1444),\n",
       "   (1380, 1483),\n",
       "   (1436, 1511),\n",
       "   (1620, 1315),\n",
       "   (1620, 1216),\n",
       "   (1630, 1424),\n",
       "   (1809, 1389),\n",
       "   (1806, 1283),\n",
       "   (1811, 1205)],\n",
       "  19: [(1119, 1005),\n",
       "   (1112, 1005),\n",
       "   (1164, 1005),\n",
       "   (1218, 1005),\n",
       "   (1284, 1005),\n",
       "   (1340, 1005),\n",
       "   (1322, 1162),\n",
       "   (1276, 1162),\n",
       "   (1119, 1163),\n",
       "   (1183, 1094),\n",
       "   (1183, 1141),\n",
       "   (1225, 1071),\n",
       "   (1112, 1296),\n",
       "   (1194, 1564),\n",
       "   (1272, 1449),\n",
       "   (1337, 1557),\n",
       "   (1414, 1557),\n",
       "   (1556, 1368),\n",
       "   (1556, 1316),\n",
       "   (1559, 1488),\n",
       "   (1750, 1448),\n",
       "   (1748, 1327),\n",
       "   (1748, 1272)],\n",
       "  20: [(1164, 1005),\n",
       "   (1119, 1005),\n",
       "   (1218, 1005),\n",
       "   (1284, 1005),\n",
       "   (1340, 1005),\n",
       "   (1395, 1005),\n",
       "   (1386, 1162),\n",
       "   (1322, 1162),\n",
       "   (1183, 1163),\n",
       "   (1225, 1094),\n",
       "   (1276, 1141),\n",
       "   (1276, 1071),\n",
       "   (1154, 1296),\n",
       "   (1259, 1564),\n",
       "   (1283, 1449),\n",
       "   (1380, 1557),\n",
       "   (1436, 1557),\n",
       "   (1620, 1368),\n",
       "   (1620, 1316),\n",
       "   (1630, 1488),\n",
       "   (1809, 1448),\n",
       "   (1806, 1327),\n",
       "   (1811, 1272)]},\n",
       " 'scale': 1.0579185520361991}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizing Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = train_data[10]\n",
    "\n",
    "# Convert back to [0, 255] range\n",
    "tensor_image = sample['image'] * 255.0\n",
    "\n",
    "np_image = tensor_image.numpy().astype(np.uint8)  # Convert to unsigned 8-bit integer\n",
    "\n",
    "# Transpose to [H, W, 3] from [3, H, W]\n",
    "np_image = np.transpose(np_image, (1, 2, 0))\n",
    "\n",
    "# Create figure with 1 row and 3 columns for the first set of visualizations\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 8))\n",
    "\n",
    "# Input image\n",
    "axes[0].imshow(np_image)\n",
    "axes[0].axis('off')\n",
    "axes[0].set_title('Input Image')\n",
    "\n",
    "# Room segmentation map\n",
    "axes[1].imshow(np_image)\n",
    "axes[1].imshow(sample['label'][21], alpha=0.8)\n",
    "axes[1].axis('off')\n",
    "axes[1].set_title('Room Labels')\n",
    "\n",
    "# Icon segmentation map\n",
    "axes[2].imshow(np_image)\n",
    "axes[2].imshow(sample['label'][22], alpha=0.8)\n",
    "axes[2].axis('off')\n",
    "axes[2].set_title('Icon Labels')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Now display the heatmaps, 3 heatmaps per row\n",
    "num_heatmaps = 21\n",
    "cols = 3\n",
    "rows = (num_heatmaps + cols - 1) // cols  # Calculate number of rows needed\n",
    "\n",
    "fig, axes = plt.subplots(rows, cols, figsize=(10, 3 * rows))\n",
    "\n",
    "for i in range(num_heatmaps):\n",
    "    row = i // cols\n",
    "    col = i % cols\n",
    "\n",
    "    axes[row, col].imshow(np_image)\n",
    "    axes[row, col].imshow(sample['label'][i], alpha=0.8)\n",
    "    axes[row, col].axis('off')\n",
    "    axes[row, col].set_title(f'Heatmap {i+1}')\n",
    "\n",
    "# If there are empty spaces in the last row (if heatmaps < total subplots), hide them\n",
    "for j in range(i + 1, rows * cols):\n",
    "    fig.delaxes(axes[j // cols, j % cols])  # Remove unused subplots\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "===================================================================================================================\n",
       "Layer (type:depth-idx)                                            Output Shape              Param #\n",
       "===================================================================================================================\n",
       "DeepLabV3Plus                                                     [25, 12, 256, 256]        --\n",
       "├─Backbone: 1-1                                                   [25, 24, 64, 64]          --\n",
       "│    └─EfficientNet: 2-1                                          --                        1,409,000\n",
       "│    │    └─Sequential: 3-1                                       --                        7,700,994\n",
       "├─ASPP: 1-2                                                       [25, 256, 8, 8]           --\n",
       "│    └─Conv2d: 2-2                                                [25, 256, 8, 8]           360,448\n",
       "│    └─AtrousConv: 2-3                                            [25, 256, 8, 8]           --\n",
       "│    │    └─DepthwiseSeparableConv: 3-2                           [25, 256, 8, 8]           373,632\n",
       "│    │    └─ChannelAttention: 3-3                                 [25, 256, 8, 8]           8,464\n",
       "│    └─AtrousConv: 2-4                                            [25, 256, 8, 8]           --\n",
       "│    │    └─DepthwiseSeparableConv: 3-4                           [25, 256, 8, 8]           373,632\n",
       "│    │    └─ChannelAttention: 3-5                                 [25, 256, 8, 8]           8,464\n",
       "│    └─AtrousConv: 2-5                                            [25, 256, 8, 8]           --\n",
       "│    │    └─DepthwiseSeparableConv: 3-6                           [25, 256, 8, 8]           373,632\n",
       "│    │    └─ChannelAttention: 3-7                                 [25, 256, 8, 8]           8,464\n",
       "│    └─Sequential: 2-6                                            [25, 256, 1, 1]           --\n",
       "│    │    └─AdaptiveAvgPool2d: 3-8                                [25, 1408, 1, 1]          --\n",
       "│    │    └─Conv2d: 3-9                                           [25, 256, 1, 1]           360,448\n",
       "│    │    └─BatchNorm2d: 3-10                                     [25, 256, 1, 1]           512\n",
       "│    │    └─ReLU: 3-11                                            [25, 256, 1, 1]           --\n",
       "│    └─Sequential: 2-7                                            [25, 256, 8, 8]           --\n",
       "│    │    └─Conv2d: 3-12                                          [25, 256, 8, 8]           327,680\n",
       "│    │    └─BatchNorm2d: 3-13                                     [25, 256, 8, 8]           512\n",
       "│    │    └─ReLU: 3-14                                            [25, 256, 8, 8]           --\n",
       "├─Decoder: 1-3                                                    [25, 12, 256, 256]        --\n",
       "│    └─Sequential: 2-8                                            [25, 48, 64, 64]          --\n",
       "│    │    └─Conv2d: 3-15                                          [25, 48, 64, 64]          1,152\n",
       "│    │    └─BatchNorm2d: 3-16                                     [25, 48, 64, 64]          96\n",
       "│    │    └─ReLU: 3-17                                            [25, 48, 64, 64]          --\n",
       "│    └─SpatialAttention: 2-9                                      [25, 256, 64, 64]         --\n",
       "│    │    └─Conv2d: 3-18                                          [25, 1, 64, 64]           98\n",
       "│    │    └─Sigmoid: 3-19                                         [25, 1, 64, 64]           --\n",
       "│    └─Sequential: 2-10                                           [25, 256, 64, 64]         --\n",
       "│    │    └─DepthwiseSeparableConv: 3-20                          [25, 256, 64, 64]         81,072\n",
       "│    │    └─DepthwiseSeparableConv: 3-21                          [25, 256, 64, 64]         68,352\n",
       "│    │    └─DepthwiseSeparableConv: 3-22                          [25, 256, 64, 64]         68,352\n",
       "│    └─Conv2d: 2-11                                               [25, 12, 64, 64]          3,084\n",
       "│    └─Conv2d: 2-12                                               [25, 11, 64, 64]          2,827\n",
       "│    └─Conv2d: 2-13                                               [25, 21, 64, 64]          5,397\n",
       "===================================================================================================================\n",
       "Total params: 11,536,312\n",
       "Trainable params: 11,536,312\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (Units.GIGABYTES): 47.79\n",
       "===================================================================================================================\n",
       "Input size (MB): 19.66\n",
       "Forward/backward pass size (MB): 7245.24\n",
       "Params size (MB): 40.51\n",
       "Estimated Total Size (MB): 7305.41\n",
       "==================================================================================================================="
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from model.deeplabv3plus import DeepLabV3Plus\n",
    "from torchinfo import summary\n",
    "\n",
    "model = DeepLabV3Plus(backbone='efficientnet_b2', attention=True).to('cuda')\n",
    "\n",
    "summary(model, input_size=(25, 3, 256, 256), device='cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.models import efficientnet_v2_m\n",
    "\n",
    "model = efficientnet_v2_m(weights='DEFAULT').to('cuda')\n",
    "\n",
    "print(model.features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize Class Frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

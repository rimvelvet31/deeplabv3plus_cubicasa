{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setup completed\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torchmetrics import Accuracy, JaccardIndex, MetricCollection\n",
    "from torchinfo import summary\n",
    "\n",
    "from floortrans.loaders import FloorplanSVG\n",
    "from floortrans.loaders.augmentations import Compose, ResizePaddedTorch, DictToTensor\n",
    "\n",
    "from model.deeplabv3plus import DeepLabV3Plus\n",
    "\n",
    "from scipy.stats import f_oneway, shapiro, levene\n",
    "\n",
    "# Use GPU if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Clear GPU cache to avoid memory errors\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# Set seed and deterministic behavior to ensure reproducibility\n",
    "torch.manual_seed(0)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "print('Setup completed')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test dataset size: 400\n",
      "Test images shape: torch.Size([3, 256, 256])\n",
      "Test labels shape: torch.Size([23, 256, 256])\n"
     ]
    }
   ],
   "source": [
    "img_shape = (256, 256)\n",
    "\n",
    "aug = Compose([\n",
    "    ResizePaddedTorch((0, 0), data_format='dict', size=img_shape), \n",
    "    DictToTensor()\n",
    "])\n",
    "\n",
    "test_dataset = FloorplanSVG('data/cubicasa5k/', 'test.txt', format='lmdb', augmentations=aug)\n",
    "\n",
    "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False, num_workers=0)\n",
    "\n",
    "print(f'Test dataset size: {len(test_dataset)}')\n",
    "print(f'Test images shape: {test_dataset[0][\"image\"].shape}')\n",
    "print(f'Test labels shape: {test_dataset[0][\"label\"].shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Red\\AppData\\Local\\Temp\\ipykernel_18868\\262638915.py:4: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  deeplab_base.load_state_dict(torch.load(deeplab_base_path)['model_state_dict'])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "==============================================================================================================\n",
       "Layer (type:depth-idx)                                       Output Shape              Param #\n",
       "==============================================================================================================\n",
       "DeepLabV3Plus                                                [1, 12, 256, 256]         --\n",
       "├─Backbone: 1-1                                              [1, 24, 64, 64]           --\n",
       "│    └─MobileNetV2: 2-1                                      --                        1,281,000\n",
       "│    │    └─Sequential: 3-1                                  --                        2,223,872\n",
       "├─ASPP: 1-2                                                  [1, 256, 8, 8]            --\n",
       "│    └─Conv2d: 2-2                                           [1, 256, 8, 8]            327,680\n",
       "│    └─AtrousConv: 2-3                                       [1, 256, 8, 8]            --\n",
       "│    │    └─DepthwiseSeparableConv: 3-2                      [1, 256, 8, 8]            339,712\n",
       "│    └─AtrousConv: 2-4                                       [1, 256, 8, 8]            --\n",
       "│    │    └─DepthwiseSeparableConv: 3-3                      [1, 256, 8, 8]            339,712\n",
       "│    └─AtrousConv: 2-5                                       [1, 256, 8, 8]            --\n",
       "│    │    └─DepthwiseSeparableConv: 3-4                      [1, 256, 8, 8]            339,712\n",
       "│    └─Sequential: 2-6                                       [1, 256, 1, 1]            --\n",
       "│    │    └─AdaptiveAvgPool2d: 3-5                           [1, 1280, 1, 1]           --\n",
       "│    │    └─Conv2d: 3-6                                      [1, 256, 1, 1]            327,680\n",
       "│    │    └─BatchNorm2d: 3-7                                 [1, 256, 1, 1]            512\n",
       "│    │    └─ReLU: 3-8                                        [1, 256, 1, 1]            --\n",
       "│    └─Sequential: 2-7                                       [1, 256, 8, 8]            --\n",
       "│    │    └─Conv2d: 3-9                                      [1, 256, 8, 8]            327,680\n",
       "│    │    └─BatchNorm2d: 3-10                                [1, 256, 8, 8]            512\n",
       "│    │    └─ReLU: 3-11                                       [1, 256, 8, 8]            --\n",
       "├─Decoder: 1-3                                               [1, 12, 256, 256]         --\n",
       "│    └─Sequential: 2-8                                       [1, 48, 64, 64]           --\n",
       "│    │    └─Conv2d: 3-12                                     [1, 48, 64, 64]           1,152\n",
       "│    │    └─BatchNorm2d: 3-13                                [1, 48, 64, 64]           96\n",
       "│    │    └─ReLU: 3-14                                       [1, 48, 64, 64]           --\n",
       "│    └─Sequential: 2-9                                       [1, 256, 64, 64]          --\n",
       "│    │    └─DepthwiseSeparableConv: 3-15                     [1, 256, 64, 64]          81,072\n",
       "│    │    └─DepthwiseSeparableConv: 3-16                     [1, 256, 64, 64]          68,352\n",
       "│    │    └─DepthwiseSeparableConv: 3-17                     [1, 256, 64, 64]          68,352\n",
       "│    └─Conv2d: 2-10                                          [1, 12, 64, 64]           3,084\n",
       "│    └─Conv2d: 2-11                                          [1, 11, 64, 64]           2,827\n",
       "│    └─Conv2d: 2-12                                          [1, 21, 64, 64]           5,397\n",
       "==============================================================================================================\n",
       "Total params: 5,738,404\n",
       "Trainable params: 5,738,404\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (Units.GIGABYTES): 1.44\n",
       "==============================================================================================================\n",
       "Input size (MB): 0.79\n",
       "Forward/backward pass size (MB): 224.37\n",
       "Params size (MB): 17.83\n",
       "Estimated Total Size (MB): 242.98\n",
       "=============================================================================================================="
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deeplab_base_path = 'best_models/dlv3p_mobilenet_v2_base.pt'\n",
    "\n",
    "deeplab_base = DeepLabV3Plus(backbone='mobilenet_v2', attention=False)\n",
    "deeplab_base.load_state_dict(torch.load(deeplab_base_path)['model_state_dict'])\n",
    "deeplab_base.to(device)\n",
    "\n",
    "summary(deeplab_base, input_size=(1, 3, img_shape[0], img_shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Red\\AppData\\Local\\Temp\\ipykernel_18868\\962531979.py:4: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  deeplab_casa.load_state_dict(torch.load(deeplab_casa_path)['model_state_dict'])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for DeepLabV3Plus:\n\tMissing key(s) in state_dict: \"aspp.atrous_conv_rate6.ca.mlp.4.weight\", \"aspp.atrous_conv_rate6.ca.mlp.4.bias\", \"aspp.atrous_conv_rate12.ca.mlp.4.weight\", \"aspp.atrous_conv_rate12.ca.mlp.4.bias\", \"aspp.atrous_conv_rate18.ca.mlp.4.weight\", \"aspp.atrous_conv_rate18.ca.mlp.4.bias\". \n\tsize mismatch for aspp.atrous_conv_rate6.ca.mlp.2.weight: copying a param with shape torch.Size([256, 16]) from checkpoint, the shape in current model is torch.Size([128, 16]).\n\tsize mismatch for aspp.atrous_conv_rate6.ca.mlp.2.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for aspp.atrous_conv_rate12.ca.mlp.2.weight: copying a param with shape torch.Size([256, 16]) from checkpoint, the shape in current model is torch.Size([128, 16]).\n\tsize mismatch for aspp.atrous_conv_rate12.ca.mlp.2.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for aspp.atrous_conv_rate18.ca.mlp.2.weight: copying a param with shape torch.Size([256, 16]) from checkpoint, the shape in current model is torch.Size([128, 16]).\n\tsize mismatch for aspp.atrous_conv_rate18.ca.mlp.2.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m deeplab_casa_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbest_models/dlv3p_mobilenet_v2_ca_sa.pt\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m      3\u001b[0m deeplab_casa \u001b[38;5;241m=\u001b[39m DeepLabV3Plus(backbone\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmobilenet_v2\u001b[39m\u001b[38;5;124m'\u001b[39m, attention\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m----> 4\u001b[0m \u001b[43mdeeplab_casa\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_state_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdeeplab_casa_path\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmodel_state_dict\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m deeplab_casa\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m      7\u001b[0m summary(deeplab_casa, input_size\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m3\u001b[39m, img_shape[\u001b[38;5;241m0\u001b[39m], img_shape[\u001b[38;5;241m1\u001b[39m]))\n",
      "File \u001b[1;32mc:\\Users\\Red\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2215\u001b[0m, in \u001b[0;36mModule.load_state_dict\u001b[1;34m(self, state_dict, strict, assign)\u001b[0m\n\u001b[0;32m   2210\u001b[0m         error_msgs\u001b[38;5;241m.\u001b[39minsert(\n\u001b[0;32m   2211\u001b[0m             \u001b[38;5;241m0\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMissing key(s) in state_dict: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m   2212\u001b[0m                 \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m missing_keys)))\n\u001b[0;32m   2214\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(error_msgs) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m-> 2215\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mError(s) in loading state_dict for \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m   2216\u001b[0m                        \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(error_msgs)))\n\u001b[0;32m   2217\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _IncompatibleKeys(missing_keys, unexpected_keys)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for DeepLabV3Plus:\n\tMissing key(s) in state_dict: \"aspp.atrous_conv_rate6.ca.mlp.4.weight\", \"aspp.atrous_conv_rate6.ca.mlp.4.bias\", \"aspp.atrous_conv_rate12.ca.mlp.4.weight\", \"aspp.atrous_conv_rate12.ca.mlp.4.bias\", \"aspp.atrous_conv_rate18.ca.mlp.4.weight\", \"aspp.atrous_conv_rate18.ca.mlp.4.bias\". \n\tsize mismatch for aspp.atrous_conv_rate6.ca.mlp.2.weight: copying a param with shape torch.Size([256, 16]) from checkpoint, the shape in current model is torch.Size([128, 16]).\n\tsize mismatch for aspp.atrous_conv_rate6.ca.mlp.2.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for aspp.atrous_conv_rate12.ca.mlp.2.weight: copying a param with shape torch.Size([256, 16]) from checkpoint, the shape in current model is torch.Size([128, 16]).\n\tsize mismatch for aspp.atrous_conv_rate12.ca.mlp.2.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for aspp.atrous_conv_rate18.ca.mlp.2.weight: copying a param with shape torch.Size([256, 16]) from checkpoint, the shape in current model is torch.Size([128, 16]).\n\tsize mismatch for aspp.atrous_conv_rate18.ca.mlp.2.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128])."
     ]
    }
   ],
   "source": [
    "deeplab_casa_path = 'best_models/dlv3p_mobilenet_v2_ca_sa.pt'\n",
    "\n",
    "deeplab_casa = DeepLabV3Plus(backbone='mobilenet_v2', attention=True)\n",
    "deeplab_casa.load_state_dict(torch.load(deeplab_casa_path)['model_state_dict'])\n",
    "deeplab_casa.to(device)\n",
    "\n",
    "summary(deeplab_casa, input_size=(1, 3, img_shape[0], img_shape[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate models on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_combined_metrics(room_class_metrics, icon_class_metrics, combined_class_freq):\n",
    "    combined_acc = torch.cat([room_class_metrics['acc'].compute(), icon_class_metrics['acc'].compute()])\n",
    "    combined_iou = torch.cat([room_class_metrics['iou'].compute(), icon_class_metrics['iou'].compute()])\n",
    "\n",
    "    combined_mpa = combined_acc.mean()\n",
    "    combined_miou = combined_iou.mean()\n",
    "\n",
    "    # fwiou\n",
    "    total_pixels = combined_class_freq.sum()\n",
    "    combined_fwiou = (combined_class_freq / total_pixels * combined_iou).sum()\n",
    "\n",
    "    return {\n",
    "        'mpa': combined_mpa.item(),\n",
    "        'cpa': combined_acc.tolist(),\n",
    "        'miou': combined_miou.item(),\n",
    "        'fwiou': combined_fwiou.item()\n",
    "    }\n",
    "\n",
    "\n",
    "def evaluate(model, model_name, loader, device):\n",
    "    model.eval()\n",
    "\n",
    "    # Evaluation metrics \n",
    "    room_mpa = Accuracy(task='multiclass', num_classes=12, average='macro').to(device)\n",
    "    room_cpa = Accuracy(task='multiclass', num_classes=12, average='none').to(device)\n",
    "    room_miou = JaccardIndex(task='multiclass', num_classes=12, average='macro').to(device)\n",
    "    room_fwiou = JaccardIndex(task='multiclass', num_classes=12, average='weighted').to(device)\n",
    "\n",
    "    icon_mpa = Accuracy(task='multiclass', num_classes=11, average='macro').to(device)\n",
    "    icon_cpa = Accuracy(task='multiclass', num_classes=11, average='none').to(device)\n",
    "    icon_miou = JaccardIndex(task='multiclass', num_classes=11, average='macro').to(device)\n",
    "    icon_fwiou = JaccardIndex(task='multiclass', num_classes=11, average='weighted').to(device)\n",
    "\n",
    "    # For computing combined metrics\n",
    "    room_class_metrics = MetricCollection({\n",
    "        'acc': Accuracy(task='multiclass', num_classes=12, average=None),\n",
    "        'iou': JaccardIndex(task='multiclass', num_classes=12, average=None)     \n",
    "    }).to(device)\n",
    "\n",
    "    icon_class_metrics = MetricCollection({\n",
    "        'acc': Accuracy(task='multiclass', num_classes=11, average=None),\n",
    "        'iou': JaccardIndex(task='multiclass', num_classes=11, average=None)     \n",
    "    }).to(device)\n",
    "\n",
    "    # To compute combined fwiou\n",
    "    combined_class_freq = torch.zeros(23).to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(loader, desc=f'Evaluating {model_name}'):\n",
    "            # Extract input images and labels\n",
    "            images = batch['image'].float().to(device)\n",
    "            room_labels = batch['label'][:, 21].long().to(device)\n",
    "            icon_labels = batch['label'][:, 22].long().to(device)\n",
    "\n",
    "            # Get raw outputs (omitted heatmap output)\n",
    "            room_logits, icon_logits, _ = model(images)\n",
    "\n",
    "            # Get predictions\n",
    "            room_preds = room_logits.argmax(dim=1)\n",
    "            icon_preds = icon_logits.argmax(dim=1)\n",
    "\n",
    "            # Update metrics\n",
    "            room_mpa(room_preds, room_labels)\n",
    "            room_cpa(room_preds, room_labels)\n",
    "            room_miou(room_preds, room_labels)\n",
    "            room_fwiou(room_preds, room_labels)\n",
    "            icon_mpa(icon_preds, icon_labels)\n",
    "            icon_cpa(icon_preds, icon_labels)\n",
    "            icon_miou(icon_preds, icon_labels)\n",
    "            icon_fwiou(icon_preds, icon_labels)\n",
    "\n",
    "            room_class_metrics(room_preds, room_labels)\n",
    "            icon_class_metrics(icon_preds, icon_labels)\n",
    "\n",
    "            # Update combined class frequency\n",
    "            combined_class_freq[:12] += torch.bincount(room_labels.flatten(), minlength=12)\n",
    "            combined_class_freq[12:] += torch.bincount(icon_labels.flatten(), minlength=11)\n",
    "\n",
    "    # Get actual metric values and round to 4 decimal places\n",
    "    room_mpa_val = round(room_mpa.compute().item(), 4)\n",
    "    room_miou_val = round(room_miou.compute().item(), 4)\n",
    "    room_fwiou_val = round(room_fwiou.compute().item(), 4)\n",
    "    icon_mpa_val = round(icon_mpa.compute().item(), 4)\n",
    "    icon_miou_val = round(icon_miou.compute().item(), 4)\n",
    "    icon_fwiou_val = round(icon_fwiou.compute().item(), 4)\n",
    "    \n",
    "    room_cpa_list = [round(val, 4) for val in room_cpa.compute().tolist()]\n",
    "    icon_cpa_list = [round(val, 4) for val in icon_cpa.compute().tolist()]\n",
    "\n",
    "    # Compute combined metrics\n",
    "    combined_metrics = compute_combined_metrics(room_class_metrics, icon_class_metrics, combined_class_freq)\n",
    "    combined_mpa = round(combined_metrics['mpa'], 4)\n",
    "    combined_miou = round(combined_metrics['miou'], 4)\n",
    "    combined_fwiou = round(combined_metrics['fwiou'], 4)\n",
    "    combined_cpa = [round(val, 4) for val in combined_metrics['cpa']]\n",
    "\n",
    "    return {\n",
    "        'room_mpa': room_mpa_val,\n",
    "        'room_cpa': room_cpa_list,\n",
    "        'room_miou': room_miou_val,\n",
    "        'room_fwiou': room_fwiou_val,\n",
    "        'icon_mpa': icon_mpa_val,\n",
    "        'icon_cpa': icon_cpa_list,\n",
    "        'icon_miou': icon_miou_val,\n",
    "        'icon_fwiou': icon_fwiou_val,\n",
    "        'combined_mpa': combined_mpa,\n",
    "        'combined_cpa': combined_cpa,\n",
    "        'combined_miou': combined_miou,\n",
    "        'combined_fwiou': combined_fwiou\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deeplab_base_results = evaluate(deeplab_base, 'DeepLabV3+ Base', test_loader, device)\n",
    "deeplab_casa_results = evaluate(deeplab_casa, 'DeepLabV3+ CA & SA', test_loader, device)\n",
    "\n",
    "results_dict = {\n",
    "    'Model': ['Base DeepLabV3+', 'DeepLabV3+ w/ CA & SA'],\n",
    "    'Room MPA': [deeplab_base_results['room_mpa'], deeplab_casa_results['room_mpa']],\n",
    "    'Room mIoU': [deeplab_base_results['room_miou'], deeplab_casa_results['room_miou']],\n",
    "    'Room fWIoU': [deeplab_base_results['room_fwiou'], deeplab_casa_results['room_fwiou']],\n",
    "    'Icon MPA': [deeplab_base_results['icon_mpa'], deeplab_casa_results['icon_mpa']],\n",
    "    'Icon mIoU': [deeplab_base_results['icon_miou'], deeplab_casa_results['icon_miou']],\n",
    "    'Icon fWIoU': [deeplab_base_results['icon_fwiou'], deeplab_casa_results['icon_fwiou']],\n",
    "    'Combined MPA': [deeplab_base_results['combined_mpa'], deeplab_casa_results['combined_mpa']],\n",
    "    'Combined mIoU': [deeplab_base_results['combined_miou'], deeplab_casa_results['combined_miou']],\n",
    "    'Combined fWIoU': [deeplab_base_results['combined_fwiou'], deeplab_casa_results['combined_fwiou']]\n",
    "}\n",
    "\n",
    "results_df = pd.DataFrame(results_dict)\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "room_classes = [\"Background\", \"Outdoor\", \"Wall\", \"Kitchen\", \"Living Room\", \"Bedroom\", \"Bath\", \"Hallway\", \"Railing\", \"Storage\", \"Garage\", \"Other rooms\"]\n",
    "icon_classes = [\"Empty\", \"Window\", \"Door\", \"Closet\", \"Electr. Appl.\", \"Toilet\", \"Sink\", \"Sauna bench\", \"Fire Place\", \"Bathtub\", \"Chimney\"]\n",
    "combined_classes = room_classes + icon_classes\n",
    "\n",
    "room_class_acc = { room_classes[i]: [deeplab_base_results['room_cpa'][i], deeplab_casa_results['room_cpa'][i]] for i in range(len(room_classes)) }\n",
    "icon_class_acc = { icon_classes[i]: [deeplab_base_results['icon_cpa'][i], deeplab_casa_results['icon_cpa'][i]] for i in range(len(icon_classes)) }\n",
    "combined_class_acc = { combined_classes[i]: [deeplab_base_results['combined_cpa'][i], deeplab_casa_results['combined_cpa'][i]] for i in range(len(combined_classes)) }\n",
    "\n",
    "room_class_acc_df = pd.DataFrame(room_class_acc, index=['DeepLabV3+ Base', 'DeepLabV3+ CA & SA'])\n",
    "icon_class_acc_df = pd.DataFrame(icon_class_acc, index=['DeepLabV3+ Base', 'DeepLabV3+ CA & SA'])\n",
    "combined_class_acc_df = pd.DataFrame(combined_class_acc, index=['DeepLabV3+ Base', 'DeepLabV3+ CA & SA'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "room_class_acc_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "icon_class_acc_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Research Question 1\n",
    "What is the level of accuracy of the modified DeepLabv3+ with CA and SA modules for segmenting both core floor plan objects and furniture in terms of:\n",
    "- Class Pixel Accuracy (Class Acc)\n",
    "- Overall Pixel Accuracy (Acc.)\n",
    "- Mean Intersection over Union (mIoU)\n",
    "- Frequency Weighted Intersection over Union (fwIoU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sop1_agg_results = pd.DataFrame({\n",
    "    'Model': ['Base DeepLabV3+', 'DeepLabV3+ w/ CA & SA'],\n",
    "    'mPA': [deeplab_base_results['combined_mpa'], deeplab_casa_results['combined_mpa']],\n",
    "    'mIoU': [deeplab_base_results['combined_miou'], deeplab_casa_results['combined_miou']],\n",
    "    'fWIoU': [deeplab_base_results['combined_fwiou'], deeplab_casa_results['combined_fwiou']]\n",
    "})\n",
    "\n",
    "sop1_agg_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.catplot(kind='bar', data=sop1_agg_results, x='Model', y='mPA', hue='Model')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sop1_class_results = pd.DataFrame({\n",
    "    'Class': combined_classes,\n",
    "    'DeepLabV3+ Base': deeplab_base_results['combined_cpa'],\n",
    "    'DeepLabV3+ CA & SA': deeplab_casa_results['combined_cpa']\n",
    "})\n",
    "\n",
    "sop1_class_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Research Question 2\n",
    "What is the level of accuracy of the modified DeepLabv3+ with CA and SA modules for segmenting only core floor plan objects in terms of:\n",
    "- Class Pixel Accuracy (Class Acc)\n",
    "- Overall Pixel Accuracy (Acc.)\n",
    "- Mean Intersection over Union (mIoU)\n",
    "- Frequency Weighted Intersection over Union (fwIoU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sop2_agg_results = pd.DataFrame({\n",
    "    'Model': ['Base DeepLabV3+', 'DeepLabV3+ w/ CA & SA'],\n",
    "    'mPA': [deeplab_base_results['room_mpa'], deeplab_casa_results['room_mpa']],\n",
    "    'mIoU': [deeplab_base_results['room_miou'], deeplab_casa_results['room_miou']],\n",
    "    'fWIoU': [deeplab_base_results['room_fwiou'], deeplab_casa_results['room_fwiou']]\n",
    "})\n",
    "\n",
    "sop2_agg_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sop2_class_results = pd.DataFrame({\n",
    "    'Class': room_classes,\n",
    "    'DeepLabV3+ Base': deeplab_base_results['room_cpa'],\n",
    "    'DeepLabV3+ w/ CA & SA': deeplab_casa_results['room_cpa']\n",
    "})\n",
    "\n",
    "sop2_class_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Research Question 3\n",
    "Is there a significant difference in the performance of the modified DeepLabv3+ with CA and SA modules compared to the unmodified base model in terms of:\n",
    "- Overall Pixel Accuracy (Acc.)\n",
    "- Mean Intersection over Union (mIoU)\n",
    "- Frequency Weighted Intersection over Union (fwIoU)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute per-image mPA, mIoU, and fwIoU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_per_image(model, model_name, loader, device):\n",
    "    # Store as tensors for efficient computation\n",
    "    mpa = torch.tensor([]).to(device)\n",
    "    miou= torch.tensor([]).to(device)\n",
    "    fwiou = torch.tensor([]).to(device)\n",
    "\n",
    "    # Use combined metrics for this\n",
    "    room_class_metrics = MetricCollection({\n",
    "        'acc': Accuracy(task='multiclass', num_classes=12, average=None),\n",
    "        'iou': JaccardIndex(task='multiclass', num_classes=12, average=None)     \n",
    "    }).to(device)\n",
    "\n",
    "    icon_class_metrics = MetricCollection({\n",
    "        'acc': Accuracy(task='multiclass', num_classes=11, average=None),\n",
    "        'iou': JaccardIndex(task='multiclass', num_classes=11, average=None)     \n",
    "    }).to(device)\n",
    "\n",
    "    # To compute combined fwiou\n",
    "    combined_class_freq = torch.zeros(23).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(loader, desc=f'Evaluating {model_name}'):\n",
    "            # Extract input images and labels\n",
    "            images = batch['image'].float().to(device)\n",
    "            room_labels = batch['label'][:, 21].long().to(device)\n",
    "            icon_labels = batch['label'][:, 22].long().to(device)\n",
    "\n",
    "            # Get raw outputs (omitted heatmap output)\n",
    "            room_logits, icon_logits, _ = model(images)\n",
    "\n",
    "            # Get predictions\n",
    "            room_preds = room_logits.argmax(dim=1)\n",
    "            icon_preds = icon_logits.argmax(dim=1)\n",
    "\n",
    "            # Update metrics\n",
    "            room_class_metrics(room_preds, room_labels)\n",
    "            icon_class_metrics(icon_preds, icon_labels)\n",
    "\n",
    "            # Update combined class frequency\n",
    "            combined_class_freq[:12] += torch.bincount(room_labels.flatten(), minlength=12)\n",
    "            combined_class_freq[12:] += torch.bincount(icon_labels.flatten(), minlength=11)\n",
    "\n",
    "            # Compute per image metrics\n",
    "            room_acc = room_class_metrics['acc'].compute().cpu().numpy()\n",
    "            icon_acc = icon_class_metrics['acc'].compute().cpu().numpy()\n",
    "            room_iou = room_class_metrics['iou'].compute().cpu().numpy()\n",
    "            icon_iou = icon_class_metrics['iou'].compute().cpu().numpy()\n",
    "\n",
    "            combined_acc = torch.cat([torch.tensor(room_acc).to(device), torch.tensor(icon_acc).to(device)])\n",
    "            combined_iou = torch.cat([torch.tensor(room_iou).to(device), torch.tensor(icon_iou).to(device)])\n",
    "\n",
    "            mpa_img = combined_acc.mean().item()\n",
    "            miou_img = combined_iou.mean().item()\n",
    "\n",
    "            total_pixels = combined_class_freq.sum().item()\n",
    "            fwiou_img = (combined_class_freq / total_pixels * combined_iou).sum().item()\n",
    "\n",
    "            # Append to tensors\n",
    "            mpa = torch.cat([mpa, torch.tensor([mpa_img]).to(device)])\n",
    "            miou = torch.cat([miou, torch.tensor([miou_img]).to(device)])\n",
    "            fwiou = torch.cat([fwiou, torch.tensor([fwiou_img]).to(device)])\n",
    "\n",
    "    return { 'mpa': mpa, 'miou': miou, 'fwiou': fwiou }\n",
    "\n",
    "\n",
    "base_per_img_res = evaluate_per_image(deeplab_base, 'DeepLabV3+ Base', test_loader, device)\n",
    "casa_per_img_res = evaluate_per_image(deeplab_casa, 'DeepLabV3+ CA & SA', test_loader, device)\n",
    "\n",
    "mPA_base = base_per_img_res['mpa'].tolist()\n",
    "mPA_modified = casa_per_img_res['mpa'].tolist()\n",
    "\n",
    "mIoU_base = base_per_img_res['miou'].tolist()\n",
    "mIoU_modified = casa_per_img_res['miou'].tolist()\n",
    "\n",
    "fwIoU_base = base_per_img_res['fwiou'].tolist()\n",
    "fwIoU_modified = casa_per_img_res['fwiou'].tolist()\n",
    "\n",
    "print('mPA')\n",
    "print('Base:', mPA_base[:5])\n",
    "print('Mod: ', mPA_modified[:5])\n",
    "print()\n",
    "\n",
    "print('mIoU')\n",
    "print('Base:', mIoU_base[:5])\n",
    "print('Mod: ', mIoU_modified[:5])\n",
    "print()\n",
    "\n",
    "print('fwIoU')\n",
    "print('Base:', mIoU_base[:5])\n",
    "print('Mod: ', mIoU_modified[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Statistical Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_stat_mPA, p_value_mPA = f_oneway(mPA_modified, mPA_base)\n",
    "f_stat_mIoU, p_value_mIoU = f_oneway(mIoU_modified, mIoU_base)\n",
    "f_stat_fwIoU, p_value_fwIoU = f_oneway(fwIoU_modified, fwIoU_base)\n",
    "\n",
    "sop3_results = pd.DataFrame({\n",
    "    'Metric': ['mPA', 'mIoU', 'fwIoU'],\n",
    "    'F-Statistic': [f_stat_mPA, f_stat_mIoU, f_stat_fwIoU],\n",
    "    'P-Value': [p_value_mPA, p_value_mIoU, p_value_fwIoU],\n",
    "    'Significant Difference': ['Yes' if p_value_mPA < 0.05 else 'No', \n",
    "                               'Yes' if p_value_mIoU < 0.05 else 'No', \n",
    "                               'Yes' if p_value_fwIoU < 0.05 else 'No']\n",
    "})\n",
    "\n",
    "sop3_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save results as spreadsheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.ExcelWriter('test_results/experiments.xlsx') as writer:\n",
    "    sop1_agg_results.to_excel(writer, sheet_name='SOP1 Aggregated')\n",
    "    sop1_class_results.to_excel(writer, sheet_name='SOP1 Class-wise')\n",
    "    sop2_agg_results.to_excel(writer, sheet_name='SOP2 Aggregated')\n",
    "    sop2_class_results.to_excel(writer, sheet_name='SOP2 Class-wise')\n",
    "    sop3_results.to_excel(writer, sheet_name='SOP3')\n",
    "\n",
    "print('Results saved to spreadsheet')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

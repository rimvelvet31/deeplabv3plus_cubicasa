{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory has been released.\n",
      "Using device: NVIDIA GeForce RTX 3060 Laptop GPU\n",
      "Setup complete.\n"
     ]
    }
   ],
   "source": [
    "# General\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "# PyTorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from torchvision import transforms\n",
    "from torchinfo import summary\n",
    "from torchmetrics import MetricCollection, Accuracy, JaccardIndex\n",
    "\n",
    "# CubiCasa\n",
    "from floortrans.loaders import FloorplanSVG\n",
    "from floortrans.loaders.augmentations import (RandomCropToSizeTorch,\n",
    "                                              ResizePaddedTorch,\n",
    "                                              Compose,\n",
    "                                              DictToTensor,\n",
    "                                              ColorJitterTorch,\n",
    "                                              RandomRotations)\n",
    "\n",
    "# Model\n",
    "from model.deeplabv3plus import DeepLabV3Plus\n",
    "\n",
    "# Release GPU memory\n",
    "torch.cuda.empty_cache()\n",
    "print('GPU memory has been released.')\n",
    "\n",
    "# Check if GPU is available\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "    print(f'Using device: {torch.cuda.get_device_name(0)}')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "    print('Using device: CPU')\n",
    "\n",
    "\n",
    "print('Setup complete.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing and Augmentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_SIZE = (256, 256)\n",
    "\n",
    "train_aug = Compose([\n",
    "    # transforms.RandomChoice([\n",
    "    #     RandomCropToSizeTorch(data_format='dict', size=IMAGE_SIZE),\n",
    "    #     ResizePaddedTorch((0, 0), data_format='dict', size=IMAGE_SIZE)\n",
    "    # ]),\n",
    "    ResizePaddedTorch((0, 0), data_format='dict', size=IMAGE_SIZE),\n",
    "    RandomRotations(format='cubi'),\n",
    "    DictToTensor(),\n",
    "    ColorJitterTorch(b_var=0.2, c_var=0.2, s_var=0.2)\n",
    "])\n",
    "\n",
    "val_aug = Compose([\n",
    "    ResizePaddedTorch((0, 0), data_format='dict', size=IMAGE_SIZE),\n",
    "    DictToTensor()\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set size: 4200\n",
      "Validation set size: 400\n"
     ]
    }
   ],
   "source": [
    "DATA_PATH = 'data/cubicasa5k/'\n",
    "TRAIN_PATH = 'train.txt'\n",
    "VAL_PATH = 'val.txt'\n",
    "FORMAT = 'lmdb'\n",
    "\n",
    "train_set = FloorplanSVG(\n",
    "    DATA_PATH, \n",
    "    TRAIN_PATH, \n",
    "    format=FORMAT, \n",
    "    augmentations=train_aug\n",
    ")\n",
    "\n",
    "# Reduce training set for faster training (temporary)\n",
    "# train_set = Subset(full_train_set, list(range(1600)))\n",
    "\n",
    "val_set = FloorplanSVG(\n",
    "    DATA_PATH, \n",
    "    VAL_PATH, \n",
    "    format=FORMAT, \n",
    "    augmentations=val_aug\n",
    ")\n",
    "\n",
    "print('Train set size:', len(train_set))\n",
    "print('Validation set size:', len(val_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = train_set[10]\n",
    "\n",
    "print('Image shape:', sample['image'].shape)\n",
    "print('Label shape (overall):', sample['label'].shape)\n",
    "\n",
    "# Room and icon segmentation maps\n",
    "print('\\nLabel shape (rooms): ', sample['label'][21].shape)\n",
    "print('Label shape (icons):', sample['label'][22].shape)\n",
    "print()\n",
    "\n",
    "# Heatmaps\n",
    "for i in range(21):\n",
    "    print(f'Label shape (heatmap {i+1}):', sample['label'][i].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Image: ', sample['image'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Label: ', sample['label'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize Images and Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert back to [0, 255] range\n",
    "tensor_image = sample['image'] * 255.0\n",
    "\n",
    "np_image = tensor_image.numpy().astype(np.uint8)  # Convert to unsigned 8-bit integer\n",
    "\n",
    "# Transpose to [H, W, 3] from [3, H, W]\n",
    "np_image = np.transpose(np_image, (1, 2, 0))\n",
    "\n",
    "# Create figure with 1 row and 3 columns for the first set of visualizations\n",
    "fig, axes = plt.subplots(1, 3, figsize=(10, 3))\n",
    "\n",
    "# Input image\n",
    "axes[0].imshow(np_image)\n",
    "axes[0].axis('off')  # Remove the axes\n",
    "axes[0].set_title('Input Image')\n",
    "\n",
    "# Room segmentation map\n",
    "axes[1].imshow(sample['label'][21])\n",
    "axes[1].axis('off')  # Remove the axes\n",
    "axes[1].set_title('Room Labels')\n",
    "\n",
    "# Icon segmentation map\n",
    "axes[2].imshow(sample['label'][22])\n",
    "axes[2].axis('off')\n",
    "axes[2].set_title('Icon Labels')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Now display the heatmaps, 3 heatmaps per row\n",
    "num_heatmaps = 21\n",
    "cols = 3\n",
    "rows = (num_heatmaps + cols - 1) // cols  # Calculate number of rows needed\n",
    "\n",
    "fig, axes = plt.subplots(rows, cols, figsize=(10, 3 * rows))\n",
    "\n",
    "for i in range(num_heatmaps):\n",
    "    row = i // cols\n",
    "    col = i % cols\n",
    "    axes[row, col].imshow(sample['label'][i])\n",
    "    axes[row, col].axis('off')\n",
    "    axes[row, col].set_title(f'Heatmap {i+1}')\n",
    "\n",
    "# If there are empty spaces in the last row (if heatmaps < total subplots), hide them\n",
    "for j in range(i + 1, rows * cols):\n",
    "    fig.delaxes(axes[j // cols, j % cols])  # Remove unused subplots\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of train dataloader: 66 batches of size 64\n",
      "Length of val dataloader: 7 batches of size 64\n",
      "\n",
      "Batch image shape:  torch.Size([64, 3, 256, 256])\n",
      "Batch label shape:  torch.Size([64, 23, 256, 256])\n"
     ]
    }
   ],
   "source": [
    "NUM_WORKERS = 0\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_set, \n",
    "    batch_size=BATCH_SIZE, \n",
    "    num_workers=NUM_WORKERS, \n",
    "    shuffle=True, \n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_set, \n",
    "    batch_size=BATCH_SIZE, \n",
    "    num_workers=NUM_WORKERS, \n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "print(f'Length of train dataloader: {len(train_loader)} batches of size {BATCH_SIZE}')\n",
    "print(f'Length of val dataloader: {len(val_loader)} batches of size {BATCH_SIZE}')\n",
    "\n",
    "batch_sample = next(iter(train_loader))\n",
    "print('\\nBatch image shape: ', batch_sample['image'].shape)\n",
    "print('Batch label shape: ', batch_sample['label'].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Setup\n",
    "\n",
    "For reference, here are the 23 classes:  \n",
    "\n",
    "- **Rooms (12):** \"Background\", \"Outdoor\", \"Wall\", \"Kitchen\", \"Living Room\" ,\"Bed Room\", \"Bath\", \"Entry\", \"Railing\", \"Storage\", \"Garage\", \"Undefined\"  \n",
    "\n",
    "- **Icons (11):** \"No Icon\", \"Window\", \"Door\", \"Closet\", \"Electrical Applience\" ,\"Toilet\", \"Sink\", \"Sauna Bench\", \"Fire Place\", \"Bathtub\", \"Chimney\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==============================================================================================================\n",
       "Layer (type:depth-idx)                                       Output Shape              Param #\n",
       "==============================================================================================================\n",
       "DeepLabV3Plus                                                [32, 12, 512, 512]        --\n",
       "├─Backbone: 1-1                                              [32, 24, 128, 128]        --\n",
       "│    └─MobileNetV2: 2-1                                      --                        1,281,000\n",
       "│    │    └─Sequential: 3-1                                  --                        2,223,872\n",
       "├─ASPP: 1-2                                                  [32, 256, 16, 16]         --\n",
       "│    └─Conv2d: 2-2                                           [32, 256, 16, 16]         327,680\n",
       "│    └─AtrousConv: 2-3                                       [32, 256, 16, 16]         --\n",
       "│    │    └─DepthwiseSeparableConv: 3-2                      [32, 256, 16, 16]         339,712\n",
       "│    │    └─ChannelAttention: 3-3                            [32, 256, 16, 16]         8,464\n",
       "│    └─AtrousConv: 2-4                                       [32, 256, 16, 16]         --\n",
       "│    │    └─DepthwiseSeparableConv: 3-4                      [32, 256, 16, 16]         339,712\n",
       "│    │    └─ChannelAttention: 3-5                            [32, 256, 16, 16]         8,464\n",
       "│    └─AtrousConv: 2-5                                       [32, 256, 16, 16]         --\n",
       "│    │    └─DepthwiseSeparableConv: 3-6                      [32, 256, 16, 16]         339,712\n",
       "│    │    └─ChannelAttention: 3-7                            [32, 256, 16, 16]         8,464\n",
       "│    └─Sequential: 2-6                                       [32, 256, 1, 1]           --\n",
       "│    │    └─AdaptiveAvgPool2d: 3-8                           [32, 1280, 1, 1]          --\n",
       "│    │    └─Conv2d: 3-9                                      [32, 256, 1, 1]           327,680\n",
       "│    │    └─BatchNorm2d: 3-10                                [32, 256, 1, 1]           512\n",
       "│    │    └─ReLU: 3-11                                       [32, 256, 1, 1]           --\n",
       "│    └─Sequential: 2-7                                       [32, 256, 16, 16]         --\n",
       "│    │    └─Conv2d: 3-12                                     [32, 256, 16, 16]         327,680\n",
       "│    │    └─BatchNorm2d: 3-13                                [32, 256, 16, 16]         512\n",
       "│    │    └─ReLU: 3-14                                       [32, 256, 16, 16]         --\n",
       "├─Decoder: 1-3                                               [32, 12, 512, 512]        --\n",
       "│    └─Sequential: 2-8                                       [32, 48, 128, 128]        --\n",
       "│    │    └─Conv2d: 3-15                                     [32, 48, 128, 128]        1,152\n",
       "│    │    └─BatchNorm2d: 3-16                                [32, 48, 128, 128]        96\n",
       "│    │    └─ReLU: 3-17                                       [32, 48, 128, 128]        --\n",
       "│    └─SpatialAttention: 2-9                                 [32, 256, 128, 128]       --\n",
       "│    │    └─Conv2d: 3-18                                     [32, 1, 128, 128]         98\n",
       "│    │    └─Sigmoid: 3-19                                    [32, 1, 128, 128]         --\n",
       "│    └─Sequential: 2-10                                      [32, 256, 128, 128]       --\n",
       "│    │    └─DepthwiseSeparableConv: 3-20                     [32, 256, 128, 128]       81,072\n",
       "│    │    └─DepthwiseSeparableConv: 3-21                     [32, 256, 128, 128]       68,352\n",
       "│    └─Conv2d: 2-11                                          [32, 12, 128, 128]        3,084\n",
       "│    └─Conv2d: 2-12                                          [32, 11, 128, 128]        2,827\n",
       "│    └─Conv2d: 2-13                                          [32, 21, 128, 128]        5,397\n",
       "==============================================================================================================\n",
       "Total params: 5,695,542\n",
       "Trainable params: 5,695,542\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (Units.GIGABYTES): 148.18\n",
       "==============================================================================================================\n",
       "Input size (MB): 100.66\n",
       "Forward/backward pass size (MB): 25501.92\n",
       "Params size (MB): 17.66\n",
       "Estimated Total Size (MB): 25620.24\n",
       "=============================================================================================================="
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = DeepLabV3Plus(backbone='mobilenetv2', attention=True)\n",
    "model.to(device)\n",
    "\n",
    "summary(model, input_size=(32, 3, 512, 512))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Verifying output shapes\n",
    "# sample_input = torch.randn(BATCH_SIZE, 3, IMAGE_SIZE[0], IMAGE_SIZE[1]).to(device)\n",
    "\n",
    "# room_output, icon_output, heatmap_output = model(sample_input)\n",
    "# print('Room Output Shape:', room_output.shape)  # Expected: [16, 12, 256, 256]\n",
    "# print('Icon Output Shape:', icon_output.shape)  # Expected: [16, 11, 256, 256]\n",
    "# print('Heatmap Output Shape:', heatmap_output.shape)  # Expected: [16, 21, 256, 256]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loss Function: Multi-Task Uncertainty Loss "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiTaskUncertaintyLoss(nn.Module):\n",
    "    def __init__(self, num_tasks=2):\n",
    "        super().__init__()\n",
    "\n",
    "        # Learnable parameter for each task\n",
    "        self.log_sigma = nn.Parameter(torch.zeros(num_tasks))\n",
    "\n",
    "\n",
    "    def forward(self, losses):\n",
    "        \"\"\"\n",
    "        Forward pass to compute the total multi-task loss.\n",
    "        Args:\n",
    "            losses (list of tensors): List of individual task losses.\n",
    "        Returns:\n",
    "            total_loss (tensor): The final weighted multi-task loss.\n",
    "        \"\"\"\n",
    "\n",
    "        # Tensor to avoid issues with autograd\n",
    "        total_loss = torch.tensor(0.0, requires_grad=True).to(losses[0].device)\n",
    "\n",
    "        for i, loss in enumerate(losses):\n",
    "            precision_weight = torch.exp(-self.log_sigma[i])\n",
    "            task_loss = precision_weight * loss + self.log_sigma[i]\n",
    "            total_loss = total_loss + task_loss\n",
    "        \n",
    "        return total_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Updated Training and Validation Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Individual loss functions for each task\n",
    "room_criterion = nn.CrossEntropyLoss()\n",
    "icon_criterion = nn.CrossEntropyLoss()\n",
    "heatmap_criterion = nn.MSELoss()\n",
    "\n",
    "# Multi-task uncertainty loss\n",
    "multitask_criterion = MultiTaskUncertaintyLoss(num_tasks=3).to(device)\n",
    "\n",
    "# Based on CubiCasa5k training setup\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3, betas=(0.9, 0.999), eps=1e-8)\n",
    "\n",
    "# Reduce learning rate if validation loss doesnt improve for 20 epochs\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=20)\n",
    "\n",
    "# Evaluation metrics\n",
    "room_metrics = MetricCollection({\n",
    "    'mpa': Accuracy(task='multiclass', num_classes=12, average='macro'),\n",
    "    'miou': JaccardIndex(task='multiclass', num_classes=12, average='macro'),\n",
    "    'fwiou': JaccardIndex(task='multiclass', num_classes=12, average='weighted'),\n",
    "}).to(device)\n",
    "\n",
    "icon_metrics = MetricCollection({\n",
    "    'mpa': Accuracy(task='multiclass', num_classes=11, average='macro'),\n",
    "    'miou': JaccardIndex(task='multiclass', num_classes=11, average='macro'),\n",
    "    'fwiou': JaccardIndex(task='multiclass', num_classes=11, average='weighted'),\n",
    "}).to(device)\n",
    "\n",
    "\n",
    "# Training loop\n",
    "def train(model, dataloader, optimizer, device):\n",
    "    model.train()\n",
    "\n",
    "    total_loss = 0.0\n",
    "\n",
    "    # To show progress bar\n",
    "    for batch in tqdm(dataloader, desc='Training'):\n",
    "        images = batch['image'].float().to(device)\n",
    "        room_labels = batch['label'][:, 21].long().to(device)\n",
    "        icon_labels = batch['label'][:, 22].long().to(device)\n",
    "        heatmap_labels = batch['label'][:, 0:21].to(device)\n",
    "\n",
    "        # Zero out gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        room_output, icon_output, heatmap_output = model(images)\n",
    "\n",
    "        # Compute individual losses per task\n",
    "        room_loss = room_criterion(room_output, room_labels)\n",
    "        icon_loss = icon_criterion(icon_output, icon_labels)\n",
    "        heatmap_loss = heatmap_criterion(heatmap_output, heatmap_labels)\n",
    "\n",
    "        # Compute combined loss\n",
    "        combined_loss = multitask_criterion([room_loss, icon_loss, heatmap_loss])\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        combined_loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Accumulate the scalar value of the loss\n",
    "        total_loss += combined_loss.item()\n",
    "\n",
    "        # Get model predictions\n",
    "        room_preds = torch.argmax(room_output, dim=1)\n",
    "        icon_preds = torch.argmax(icon_output, dim=1)\n",
    "\n",
    "        # Update metrics\n",
    "        room_metrics.update(room_preds, room_labels)\n",
    "        icon_metrics.update(icon_preds, icon_labels)\n",
    "\n",
    "    # Compute epoch loss and metrics\n",
    "    epoch_loss = total_loss / len(dataloader)\n",
    "    epoch_room_metrics = room_metrics.compute()\n",
    "    epoch_icon_metrics = icon_metrics.compute()\n",
    "\n",
    "    # Reset metrics\n",
    "    room_metrics.reset()\n",
    "    icon_metrics.reset()\n",
    "\n",
    "    return epoch_loss, epoch_room_metrics, epoch_icon_metrics\n",
    "\n",
    "\n",
    "# Validation loop\n",
    "def validate(model, dataloader, device):\n",
    "    model.eval()\n",
    "\n",
    "    total_loss = 0.0\n",
    "\n",
    "    # Don't compute gradients\n",
    "    with torch.no_grad():\n",
    "\n",
    "        # Wrap dataloader with tqdm to show progress bar\n",
    "        for batch in tqdm(dataloader, desc='Validating'):\n",
    "            images = batch['image'].float().to(device)\n",
    "\n",
    "            room_labels = batch['label'][:, 21].long().to(device)\n",
    "            icon_labels = batch['label'][:, 22].long().to(device)\n",
    "            heatmap_labels = batch['label'][:, 0:21].to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            room_output, icon_output, heatmap_output = model(images)\n",
    "\n",
    "            # Compute individual losses\n",
    "            room_loss = room_criterion(room_output, room_labels)\n",
    "            icon_loss = icon_criterion(icon_output, icon_labels)\n",
    "            heatmap_loss = heatmap_criterion(heatmap_output, heatmap_labels)\n",
    "\n",
    "            # Compute combined loss\n",
    "            combined_loss = multitask_criterion([room_loss, icon_loss, heatmap_loss])\n",
    "\n",
    "            # Accumulate the scalar value of the loss\n",
    "            total_loss += combined_loss.item()\n",
    "\n",
    "            # Get model predictions\n",
    "            room_preds = torch.argmax(room_output, dim=1)\n",
    "            icon_preds = torch.argmax(icon_output, dim=1)\n",
    "\n",
    "            # Update metrics\n",
    "            room_metrics.update(room_preds, room_labels)\n",
    "            icon_metrics.update(icon_preds, icon_labels)\n",
    "    \n",
    "    # Compute epoch loss and metrics\n",
    "    epoch_loss = total_loss / len(dataloader)\n",
    "    epoch_room_metrics = room_metrics.compute()\n",
    "    epoch_icon_metrics = icon_metrics.compute()\n",
    "\n",
    "    # Reset metrics\n",
    "    room_metrics.reset()\n",
    "    icon_metrics.reset()\n",
    "    \n",
    "    return epoch_loss, epoch_room_metrics, epoch_icon_metrics\n",
    "\n",
    "\n",
    "# Train and validate model\n",
    "num_epochs = 50\n",
    "best_val_loss = float('inf')\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    print(f\"EPOCH {epoch+1}/{num_epochs}\")\n",
    "\n",
    "    train_loss, train_room_metrics, train_icon_metrics = train(model, train_loader, optimizer, device)\n",
    "    val_loss, val_room_metrics, val_icon_metrics = validate(model, val_loader, device)\n",
    "\n",
    "    print('\\nTRAIN RESULTS')\n",
    "    print(f'Loss: {train_loss:.4f}')\n",
    "    print(f'Rooms: {train_room_metrics}')\n",
    "    print(f'Icons: {train_icon_metrics}')\n",
    "\n",
    "    print('\\nVALIDATION RESULTS')\n",
    "    print(f'Loss: {val_loss:.4f}')\n",
    "    print(f'Rooms: {val_room_metrics}')\n",
    "    print(f'Icons: {val_icon_metrics}')\n",
    "\n",
    "    # Update learning rate based on validation loss\n",
    "    scheduler.step(val_loss)\n",
    "\n",
    "    # Save best model\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        torch.save(model.state_dict(), f'saved_models/deeplabv3plus_{model.backbone_name}.pt')\n",
    "        print(f'\\nBest model saved with validation loss: {best_val_loss:.4f}')\n",
    "    else:\n",
    "        print(f'\\nValidation loss did not improve.Best loss is still: {best_val_loss:.4f}')\n",
    "\n",
    "    print('\\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training and Validation Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EPOCHS = 400\n",
    "# OPTIMIZER = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
    "# CRITERION = MultiTaskLossWrapper(task_num=2)\n",
    "\n",
    "# def timer(start_time = None): \n",
    "#     return time.time() if start_time == None else time.time() - start_time\n",
    "\n",
    "\n",
    "# def train_evaluate(model, \n",
    "#                    train_loader, \n",
    "#                    val_loader, \n",
    "#                    device,\n",
    "#                    loss_fn,\n",
    "#                    optimizer, \n",
    "#                    epochs,\n",
    "#                    early_stop_threshold=15,\n",
    "#                    save_prefix='deeplabv3plus',\n",
    "#                    save_path='saved_models'):\n",
    "    \n",
    "#     # Store results, to be returned\n",
    "#     train_loss_list = []\n",
    "#     train_room_cpa_list = []\n",
    "#     train_room_mpa_list = []\n",
    "#     train_room_miou_list = []\n",
    "#     train_room_fwiou_list = []\n",
    "#     train_icon_cpa_list = []\n",
    "#     train_icon_mpa_list = []\n",
    "#     train_icon_miou_list = []\n",
    "#     train_icon_fwiou_list = []\n",
    "\n",
    "#     val_loss_list = []\n",
    "#     val_room_cpa_list = []\n",
    "#     val_room_mpa_list = []\n",
    "#     val_room_miou_list = []\n",
    "#     val_room_fwiou_list = []\n",
    "#     val_icon_cpa_list = []\n",
    "#     val_icon_mpa_list = []\n",
    "#     val_icon_miou_list = []\n",
    "#     val_icon_fwiou_list = []\n",
    "\n",
    "#     # Training metrics\n",
    "#     train_room_cpa = Accuracy(task='multiclass', num_classes=12, average=None).to(device)\n",
    "#     train_room_mpa = Accuracy(task='multiclass', num_classes=12, average='macro').to(device)\n",
    "#     train_room_miou = JaccardIndex(task='multiclass', num_classes=12, average='macro').to(device)\n",
    "#     train_room_fwiou = JaccardIndex(task='multiclass', num_classes=12, average='weighted').to(device)\n",
    "\n",
    "#     train_icon_cpa = Accuracy(task='multiclass', num_classes=11, average=None).to(device)\n",
    "#     train_icon_mpa = Accuracy(task='multiclass', num_classes=11, average='macro').to(device)\n",
    "#     train_icon_miou = JaccardIndex(task='multiclass', num_classes=11, average='macro').to(device)\n",
    "#     train_icon_fwiou = JaccardIndex(task='multiclass', num_classes=11, average='weighted').to(device)\n",
    "\n",
    "#     # Validation metrics\n",
    "#     val_room_cpa = Accuracy(task='multiclass', num_classes=12, average=None).to(device)\n",
    "#     val_room_mpa = Accuracy(task='multiclass', num_classes=12, average='macro').to(device)\n",
    "#     val_room_miou = JaccardIndex(task='multiclass', num_classes=12, average='macro').to(device)\n",
    "#     val_room_fwiou = JaccardIndex(task='multiclass', num_classes=12, average='weighted').to(device)\n",
    "\n",
    "#     val_icon_cpa = Accuracy(task='multiclass', num_classes=11, average=None).to(device)\n",
    "#     val_icon_mpa = Accuracy(task='multiclass', num_classes=11, average='macro').to(device)\n",
    "#     val_icon_miou = JaccardIndex(task='multiclass', num_classes=11, average='macro').to(device)\n",
    "#     val_icon_fwiou = JaccardIndex(task='multiclass', num_classes=11, average='weighted').to(device)\n",
    "    \n",
    "#     best_loss = np.inf\n",
    "#     not_improving = 0\n",
    "    \n",
    "#     # Save models in this directory\n",
    "#     os.makedirs(save_path, exist_ok=True)\n",
    "\n",
    "#     # Start timer\n",
    "#     train_start = timer()\n",
    "#     print('Start training process...')\n",
    "\n",
    "#     for epoch in range(1, epochs + 1):\n",
    "#         epoch_start = timer()\n",
    "        \n",
    "#         # Training loop\n",
    "#         print(f'Epoch {epoch} train process started...')\n",
    "#         model.train()\n",
    "\n",
    "#         epoch_train_loss = 0.0\n",
    "\n",
    "#         for batch in tqdm(train_loader):\n",
    "#             images = batch['image'].to(device)\n",
    "#             room_labels = batch['label'][:, 0].to(device)\n",
    "#             icon_labels = batch['label'][:, 1].to(device)\n",
    "\n",
    "#             # Reset gradients since PyTorch accumulates previous gradients\n",
    "#             optimizer.zero_grad()\n",
    "\n",
    "#             # Forward pass\n",
    "#             room_output, icon_output = model(images)\n",
    "\n",
    "#             # Calculate loss\n",
    "#             loss = loss_fn(room_output, icon_output, room_labels, icon_labels)\n",
    "#             epoch_train_loss += loss.item()\n",
    "\n",
    "#             # Backward pass\n",
    "#             loss.backward()\n",
    "\n",
    "#             # Update weights\n",
    "#             optimizer.step()\n",
    "\n",
    "#             # Update metrics\n",
    "#             train_room_cpa.update(room_output, room_labels)\n",
    "#             train_room_mpa.update(room_output, room_labels)\n",
    "#             train_room_miou.update(room_output, room_labels)\n",
    "#             train_room_fwiou.update(room_output, room_labels)\n",
    "\n",
    "#             train_icon_cpa.update(icon_output, icon_labels)\n",
    "#             train_icon_mpa.update(icon_output, icon_labels)\n",
    "#             train_icon_miou.update(icon_output, icon_labels)\n",
    "#             train_icon_fwiou.update(icon_output, icon_labels)\n",
    "\n",
    "#         # Calculate training metrics\n",
    "#         train_room_cpa_value = train_room_cpa.compute()\n",
    "#         train_room_mpa_value = train_room_mpa.compute().item()\n",
    "#         train_room_miou_value = train_room_miou.compute().item()\n",
    "#         train_room_fwiou_value = train_room_fwiou.compute().item()\n",
    "\n",
    "#         train_icon_cpa_value = train_icon_cpa.compute()\n",
    "#         train_icon_mpa_value = train_icon_mpa.compute().item()\n",
    "#         train_icon_miou_value = train_icon_miou.compute().item()\n",
    "#         train_icon_fwiou_value = train_icon_fwiou.compute().item()\n",
    "\n",
    "#         # Reset metrics\n",
    "#         train_room_cpa.reset()\n",
    "#         train_room_mpa.reset()\n",
    "#         train_room_miou.reset()\n",
    "#         train_room_fwiou.reset()\n",
    "\n",
    "#         train_icon_cpa.reset()\n",
    "#         train_icon_mpa.reset()\n",
    "#         train_icon_miou.reset()\n",
    "#         train_icon_fwiou.reset()\n",
    "\n",
    "        \n",
    "#         # Validation loop\n",
    "#         print(f'Epoch {epoch} validation process started...')\n",
    "#         model.eval()\n",
    "\n",
    "#         epoch_val_loss = 0.0\n",
    "\n",
    "#         with torch.no_grad():\n",
    "#             for batch in tqdm(val_loader):\n",
    "#                 images = batch['image'].to(device)\n",
    "#                 room_labels = batch['label'][:, 0].to(device)\n",
    "#                 icon_labels = batch['label'][:, 1].to(device)\n",
    "\n",
    "#                 # Get model predictions\n",
    "#                 room_output, icon_output = model(images)\n",
    "\n",
    "#                 # Calculate loss\n",
    "#                 loss = loss_fn(room_output, icon_output, room_labels, icon_labels)\n",
    "#                 epoch_val_loss += loss.item()\n",
    "\n",
    "#                 # Update metrics\n",
    "#                 val_room_cpa.update(room_output, room_labels)\n",
    "#                 val_room_mpa.update(room_output, room_labels)\n",
    "#                 val_room_miou.update(room_output, room_labels)\n",
    "#                 val_room_fwiou.update(room_output, room_labels)\n",
    "\n",
    "#                 val_icon_cpa.update(icon_output, icon_labels)\n",
    "#                 val_icon_mpa.update(icon_output, icon_labels)\n",
    "#                 val_icon_miou.update(icon_output, icon_labels)\n",
    "#                 val_icon_fwiou.update(icon_output, icon_labels)\n",
    "\n",
    "#         # Calculate validation metrics\n",
    "#         val_room_cpa_value = val_room_cpa.compute()\n",
    "#         val_room_mpa_value = val_room_mpa.compute().item()\n",
    "#         val_room_miou_value = val_room_miou.compute().item()\n",
    "#         val_room_fwiou_value = val_room_fwiou.compute().item()\n",
    "\n",
    "#         val_icon_cpa_value = val_icon_cpa.compute()\n",
    "#         val_icon_mpa_value = val_icon_mpa.compute().item()\n",
    "#         val_icon_miou_value = val_icon_miou.compute().item()\n",
    "#         val_icon_fwiou_value = val_icon_fwiou.compute().item()\n",
    "\n",
    "#         # Reset metrics\n",
    "#         val_room_cpa.reset()\n",
    "#         val_room_mpa.reset()\n",
    "#         val_room_miou.reset()\n",
    "#         val_room_fwiou.reset()\n",
    "\n",
    "#         val_icon_cpa.reset()\n",
    "#         val_icon_mpa.reset()\n",
    "#         val_icon_miou.reset()\n",
    "#         val_icon_fwiou.reset()\n",
    "\n",
    "\n",
    "#         # Print epoch results\n",
    "#         print(f'Epoch {epoch} train process is completed.')\n",
    "#         print('\\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~')\n",
    "#         print(f'\\nEpoch {epoch} train process results:\\n')\n",
    "\n",
    "#         print(f'Train Time: {timer(epoch_start):.3f} secs')\n",
    "\n",
    "#         # Combine room and icon metrics for training, including loss\n",
    "#         print(f'Train Room - Loss: {epoch_train_loss / len(train_loader):.3f}, MPA: {train_room_mpa_value:.3f}, mIOU: {train_room_miou_value:.3f}, fwIOU: {train_room_fwiou_value:.3f}')\n",
    "#         print(f'Train Icon - Loss: {epoch_train_loss / len(train_loader):.3f}, MPA: {train_icon_mpa_value:.3f}, mIOU: {train_icon_miou_value:.3f}, fwIOU: {train_icon_fwiou_value:.3f}')\n",
    "\n",
    "#         print(f'\\nVal process results:')\n",
    "\n",
    "#         # Combine room and icon metrics for validation, including loss\n",
    "#         print(f'Val Room - Loss: {epoch_val_loss / len(val_loader):.3f}, MPA: {val_room_mpa_value:.3f}, mIOU: {val_room_miou_value:.3f}, fwIOU: {val_room_fwiou_value:.3f}')\n",
    "#         print(f'Val Icon - Loss: {epoch_val_loss / len(val_loader):.3f}, MPA: {val_icon_mpa_value:.3f}, mIOU: {val_icon_miou_value:.3f}, fwIOU: {val_icon_fwiou_value:.3f}')\n",
    "\n",
    "\n",
    "#         # Append results\n",
    "#         train_loss_list.append(epoch_train_loss / len(train_loader))\n",
    "#         train_room_cpa_list.append(train_room_cpa_value)\n",
    "#         train_room_mpa_list.append(train_room_mpa_value)\n",
    "#         train_room_miou_list.append(train_room_miou_value)\n",
    "#         train_room_fwiou_list.append(train_room_fwiou_value)\n",
    "#         train_icon_cpa_list.append(train_icon_cpa_value)\n",
    "#         train_icon_mpa_list.append(train_icon_mpa_value)\n",
    "#         train_icon_miou_list.append(train_icon_miou_value)\n",
    "#         train_icon_fwiou_list.append(train_icon_fwiou_value)\n",
    "\n",
    "#         val_loss_list.append(epoch_val_loss / len(val_loader))\n",
    "#         val_room_cpa_list.append(val_room_cpa_value)\n",
    "#         val_room_mpa_list.append(val_room_mpa_value)\n",
    "#         val_room_miou_list.append(val_room_miou_value)\n",
    "#         val_room_fwiou_list.append(val_room_fwiou_value)\n",
    "#         val_icon_cpa_list.append(val_icon_cpa_value)\n",
    "#         val_icon_mpa_list.append(val_icon_mpa_value)\n",
    "#         val_icon_miou_list.append(val_icon_miou_value)\n",
    "#         val_icon_fwiou_list.append(val_icon_fwiou_value)\n",
    "\n",
    "#         # Save model if validation loss is improved\n",
    "#         if (epoch_val_loss / len(val_loader)) < best_loss:\n",
    "#             print(f'\\nLoss decreased from {best_loss:.3f} to {(epoch_val_loss / len(val_loader)):.3f}!')\n",
    "#             best_loss = (epoch_val_loss / len(val_loader))\n",
    "\n",
    "#             not_improving = 0 # Reset counter\n",
    "\n",
    "#             print('Saving the model with the best loss value...')\n",
    "#             torch.save(model.state_dict(), f'{save_path}/{save_prefix}.pt')\n",
    "        \n",
    "#         else:\n",
    "#             not_improving += 1\n",
    "#             print(f'\\nLoss did not decrease for {not_improving} epoch(s)!')\n",
    "\n",
    "#             if not_improving == early_stop_threshold:\n",
    "#                 print(f'Stopping training process because loss did not decrease for {early_stop_threshold} epochs!')\n",
    "#                 break\n",
    "        \n",
    "#         print('\\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~')\n",
    "\n",
    "#     print(f'Train process is completed in {(timer(train_start)) / 60:.3f} minutes.')\n",
    "\n",
    "\n",
    "#     return {\n",
    "#         'train_loss': train_loss_list,\n",
    "#         'train_room_cpa': train_room_cpa_list,\n",
    "#         'train_room_mpa': train_room_mpa_list,\n",
    "#         'train_room_miou': train_room_miou_list,\n",
    "#         'train_room_fwiou': train_room_fwiou_list,\n",
    "#         'train_icon_cpa': train_icon_cpa_list,\n",
    "#         'train_icon_mpa': train_icon_mpa_list,\n",
    "#         'train_icon_miou': train_icon_miou_list,\n",
    "#         'train_icon_fwiou': train_icon_fwiou_list,\n",
    "#         'val_loss': val_loss_list,\n",
    "#         'val_room_cpa': val_room_cpa_list,\n",
    "#         'val_room_mpa': val_room_mpa_list,\n",
    "#         'val_room_miou': val_room_miou_list,\n",
    "#         'val_room_fwiou': val_room_fwiou_list,\n",
    "#         'val_icon_cpa': val_icon_cpa_list,\n",
    "#         'val_icon_mpa': val_icon_mpa_list,\n",
    "#         'val_icon_miou': val_icon_miou_list,\n",
    "#         'val_icon_fwiou': val_icon_fwiou_list\n",
    "#     }\n",
    "\n",
    "\n",
    "# # Run training and validation process\n",
    "# history = train_evaluate(model,\n",
    "#                          train_loader,\n",
    "#                          val_loader,\n",
    "#                          device,\n",
    "#                          CRITERION,\n",
    "#                          OPTIMIZER,\n",
    "#                          EPOCHS,\n",
    "#                          save_prefix=f'deeplabv3plus_{model.backbone_name}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizing Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class Plot():\n",
    "#     def __init__(self, results):\n",
    "#         self.results = results\n",
    "\n",
    "#         self.visualize(metric1=\"tr_iou\", \n",
    "#                        metric2=\"val_iou\", \n",
    "#                        label1=\"Train IoU\",\n",
    "#                        label2 =\"Validation IoU\", \n",
    "#                        title=\"Mean Intersection Over Union Learning Curve\", \n",
    "#                        ylabel=\"mIoU Score\")\n",
    "\n",
    "#         self.visualize(metric1=\"tr_pa\", \n",
    "#                        metric2=\"val_pa\", \n",
    "#                        label1=\"Train PA\",\n",
    "#                        label2=\"Validation PA\", \n",
    "#                        title=\"Pixel Accuracy Learning Curve\", \n",
    "#                        ylabel=\"PA Score\")\n",
    "\n",
    "#         self.visualize(metric1=\"tr_loss\", \n",
    "#                        metric2=\"val_loss\", \n",
    "#                        label1=\"Train Loss\",\n",
    "#                        label2=\"Validation Loss\", \n",
    "#                        title=\"Loss Learning Curve\", \n",
    "#                        ylabel=\"Loss Value\")\n",
    "\n",
    "#     def plot(self, metric, label): \n",
    "#         plt.plot(self.results[metric], label=label)\n",
    "\n",
    "#     def decorate(self, ylabel, title): \n",
    "#         plt.title(title)\n",
    "#         plt.xlabel(\"Epochs\")\n",
    "#         plt.ylabel(ylabel)\n",
    "#         plt.legend()\n",
    "#         plt.show()\n",
    "\n",
    "#     def visualize(self, metric1, metric2, label1, label2, title, ylabel):\n",
    "#         plt.figure(figsize=(10, 5))\n",
    "#         self.plot(metric1, label1)\n",
    "#         self.plot(metric2, label2)\n",
    "#         self.decorate(ylabel, title)\n",
    "\n",
    "\n",
    "# Plot(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class Test():\n",
    "#     def __init__(self, model, test_loader, loss_fn, device):\n",
    "#         self.model = model\n",
    "#         self.test_loader = test_loader\n",
    "#         self.loss_fn = loss_fn\n",
    "#         self.device = device\n",
    "    \n",
    "#     def run(self):\n",
    "#         self.model.eval()\n",
    "#         test_loss = 0\n",
    "#         test_iou = 0\n",
    "#         test_pixel_acc = 0\n",
    "#         test_len = len(self.test_loader)\n",
    "\n",
    "#         imgs = []\n",
    "#         gts = []\n",
    "#         preds = []\n",
    "\n",
    "#         with torch.no_grad():\n",
    "#             for batch in tqdm(self.test_loader):\n",
    "#                 imgs_batch = batch['image']\n",
    "#                 gts_batch = batch['label']\n",
    "#                 imgs_batch, gts_batch = imgs_batch.to(self.device), gts_batch.to(self.device)\n",
    "\n",
    "#                 # Forward pass\n",
    "#                 preds_batch = self.model(imgs_batch)\n",
    "                \n",
    "#                 # Calculate metrics\n",
    "#                 metrics = Metrics(preds_batch, gts_batch, self.loss_fn)\n",
    "#                 test_loss += metrics.loss().item()\n",
    "#                 test_iou += metrics.mIOU()\n",
    "#                 test_pixel_acc += metrics.PixelAcc()\n",
    "\n",
    "#                 # Collect data for visualization\n",
    "#                 preds_batch = torch.argmax(preds_batch, dim=1)\n",
    "#                 imgs.extend(imgs_batch.cpu())\n",
    "#                 gts.extend(gts_batch.cpu())\n",
    "#                 preds.extend(preds_batch.cpu())\n",
    "\n",
    "#         # Calculate average metrics\n",
    "#         test_loss /= test_len\n",
    "#         test_iou /= test_len\n",
    "#         test_pixel_acc /= test_len\n",
    "\n",
    "#         return imgs, gts, preds, test_loss, test_iou, test_pixel_acc\n",
    "\n",
    "\n",
    "# test = Test(model, test_loader, CRITERION, device)\n",
    "# imgs, gts, preds, test_loss, test_iou, test_pixel_acc = test.run()\n",
    "\n",
    "# print(f\"Test Loss: {test_loss:.4f}\")\n",
    "# print(f\"Test mIoU: {test_iou:.4f}\")\n",
    "# print(f\"Test PA: {test_pixel_acc:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
